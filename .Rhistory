#Creating histogram
hist(mtcars$mpg, breaks = 10, xlab = "MPG (Miles per Gallon")
#Creating histogram
hist(mtcars$mpg, breaks = 10, xlab = "MPG (Miles per Gallon", main = "Histogram of MPG")
## Creating box plot
boxplot(mtcars$mpg)
## Creating box plot
boxplot(mtcars$mpg, mtcars$am)
## Creating box plot
boxplot(x = am, y = mpg, data = mtcars)
## Creating box plot
a <- cbind(mtcars$mpg, mtcars$am)
a
data(mtcars)
head(mtcars)
dim(mtcars)
boxplot(mtcars$am~mtcars$mpg)
boxplot(mtcars$mpg~mtcars$am)
## Creating box plot
boxplot(mtcars$mpg~mtcars$am, xlab = "MPG (0 = Auto, 1 = Manual")
## Creating box plot
boxplot(mtcars$mpg~mtcars$am, xlab = "Transmission Type (0 = Auto, 1 = Manual", ylab = "MPG")
## Creating box plot
boxplot(mtcars$mpg~mtcars$am, xlab = "Transmission Type (0 = Auto, 1 = Manual",
ylab = "MPG", main = "Boxplot (MPG vs Tramission type")
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(caret)
install.packages("caret")
install.packages("caret")
install.packages("caret")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
library(caret)
library(caret)
detach("package:caret", unload = TRUE)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
install.packages("ElemStatLearn")
install.packages("pgmm")
library(pgmm)
library(rpart, lib.loc = "C:/Program Files/R/R-3.6.3/library")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(caret)
data(segmentationOriginal)
View(segmentationOriginal)
inTrain = createDataPartition(segmentationOriginal$Case, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
CART_model <- train(Class ~ ., data = training,method = "rpart")
View(training)
inTrain = createDataPartition(segmentationOriginal$Case, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
View(training)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain = createDataPartition(segmentationOriginal$Case, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
set.seed(125)
CART_model <- train(Class ~ ., data = training,method = "rpart")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain = createDataPartition(segmentationOriginal$Case, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
inTrain = createDataPartition(segmentationOriginal$Case, p = 3/4, list = FALSE)
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
View(training)
CART_model <- train(Class ~ ., data = training,method = "rpart")
data(segmentationOriginal)
View(result3)
View(segmentationOriginal)
inTrain = createDataPartition(y =segmentationOriginal$Case, p = 3/4, list = FALSE)
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
View(training)
set.seed(125)
CART_model <- train(Class ~ ., data = training,method = "rpart")
training = segmentationOriginal[ inTrain,]
testing = segmentationOriginal[-inTrain,]
set.seed(125)
CART_model <- train(Class ~ ., data = training,method = "rpart")
View(segmentationOriginal)
View(segmentationOriginal)
View(training)
CART_model$finalModel
print(CART_model$finalModel)
install.packages("rattle")
library(rattle)
fancyRpartPlot(CART_model$finalModel)
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
View(newdata)
View(olive)
inTrain = createDataPartition(y =olive$Area, p = 3/4, list = FALSE)
training = olive[ inTrain,]
testing = olive[-inTrain,]
model <- train(Area ~ ., data = olive, method = "rpart")
predict(model, newdata = newdata)
library(ElemStatLearn)
install.packages("ElemStatLearn")
data(SAheart)
missClass(testSA$chd, predict(modelSA, newdata = testSA))
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
set.seed(13234)
fit <- train(chd ~ age + alcholo + obesity + tabacco + typea +
ldl, data = trainSA, method = "glm", family = "binomial")
missClass(testSA$chd, predict(modelSA, newdata = testSA))
missClass(train$chd, predict(model$SA, newdata = trainSA))
library(ElemStatLearn)
install.packages("ElemStatLearn")
install.packages("Rtools'")
install.packages("Rtools")
install.packages("Rtools")
install.packages("dplyr")
install.packages("dplyr")
install.packages("Rtools")
install.packages("ElemStatLearn")
install.packages("randomForest")
library(randomForest)
order(varImp(model), decreasing = T)
library(dplyr)
library(ggplot2)
library(caret)
library(AppliedPredictiveModeling)
library(pgmm)
library(rpart)
library(lubridate)
library(forecast)
library(e1071)
library(ElemStatLearn)
library(gbm)
library(elasticnet)
## Creating data partition
inTrain = createDataPartition(y =training_data$classe, p = 3/4, list = FALSE)
training = training_data[ inTrain,]
data_test <- read.csv("pml-testing.csv", header = TRUE, na.strings = c("NA", "#DIV/0!", ""))
data_train <- read.csv("pml-training.csv", header = TRUE, na.strings = c("NA", "#DIV/0!", ""))
colnames(data_train)
colnames(data_test)
setwd("C:/Users/lamti/Desktop/datasciencecoursera/Course 8 Practical machine learning/Week 4/Peer assessment")
data_test <- read.csv("pml-testing.csv", header = TRUE, na.strings = c("NA", "#DIV/0!", ""))
data_train <- read.csv("pml-training.csv", header = TRUE, na.strings = c("NA", "#DIV/0!", ""))
colnames(data_train)
colnames(data_test)
## remove columns that have NA as 95% of the observations for both data set
col_na_filter <- colSums(is.na(data_train))/nrow(data_train) < 0.95
training_data <- data_train[, col_na_filter == TRUE]
testing_data <- data_test[, col_na_filter == TRUE]
## Removing the first 7 variables which do not related to the training model.
training_data <- training_data[,-c(1:7)]
testing_data <- testing_data[,-c(1:7)]
## Creating data partition
inTrain = createDataPartition(y =training_data$classe, p = 3/4, list = FALSE)
training = training_data[ inTrain,]
testing = testing_data[-inTrain,]
model_rpart <- train(classe ~ ., data = training, method = "rpart")
predict_rpart <- predict(model_rpart, testing)
confusionMatrix(training$classe, predict_rpart)
rpart.plot(model_rpart$finalModel)
library(rpart.plot)
rpart.plot(model_rpart$finalModel)
model_rpart <- train(classe ~ ., data = training, method = "rpart")
predict_rpart <- predict(model_rpart, testing)
confusionMatrix(training$classe, predict_rpart)
confusionMatrix(predict_rpart, testing$problem_id)
rpart.plot(model_rpart$finalModel)
training = training_data[ inTrain,]
testing = training_data[-inTrain,]
model_rpart <- train(classe ~ ., data = training, method = "rpart")
predict_rpart <- predict(model_rpart, testing)
confusionMatrix(predict_rpart, testing$problem_id)
rpart.plot(model_rpart$finalModel)
confusionMatrix(predict_rpart, testing$classe)
rpart.plot(model_rpart$finalModel)
## Random Forest model
model_rf <- train(classe ~ ., data = training, method = "rf")
library(dplyr)
library(ggplot2)
library(caret)
library(AppliedPredictiveModeling)
library(pgmm)
library(rpart)
library(lubridate)
library(forecast)
library(e1071)
library(ElemStatLearn)
library(gbm)
library(elasticnet)
library(rpart.plot)
setwd("C:/Users/lamti/Desktop/datasciencecoursera/Course 8 Practical machine learning/Week 4/Peer assessment")
data_test <- read.csv("pml-testing.csv", header = TRUE, na.strings = c("NA", "#DIV/0!", ""))
data_train <- read.csv("pml-training.csv", header = TRUE, na.strings = c("NA", "#DIV/0!", ""))
## remove columns that have NA as 95% of the observations for both data set
col_na_filter <- colSums(is.na(data_train))/nrow(data_train) < 0.95
training_data <- data_train[, col_na_filter == TRUE]
testing_data <- data_test[, col_na_filter == TRUE]
## Removing the first 7 variables which do not related to the training model.
training_data <- training_data[,-c(1:7)]
testing_data <- testing_data[,-c(1:7)]
## Creating data partition
inTrain = createDataPartition(y =training_data$classe, p = 3/4, list = FALSE)
training = training_data[ inTrain,]
testing = training_data[-inTrain,]
model_rpart <- train(classe ~ ., data = training, method = "rpart")
predict_rpart <- predict(model_rpart, testing)
confusionMatrix(predict_rpart, testing$classe)
rpart.plot(model_rpart$finalModel)
## Random Forest model
model_rf <- train(classe ~ ., data = training, method = "rf", ntree = 100)
predict_rf <- predict(model_rf, testing)
confusionMatrix(predict_rf, testing$classe)
rf_cm <- confusionMatrix(predict_rf, testing$classe)
plot(rf_cm$table)
plot(rf_cm$table, main = "Random Forest Prediction Accuracy")
plot(rf_cm$table, col=rf_cm$byClass, main = "Random Forest Prediction Accuracy")
plot(rf_cm$table, main = "Random Forest Prediction Accuracy")
predict_gbm <- predict(model_gbm, training)
predict_gbm <- predict(model_gbm, training)
predict_gbm <- predict(model_gbm, training$classe)
model_gbm <- train(classe ~ ., data = training, method = "gbm")
library(dplyr)
library(ggplot2)
library(caret)
library(AppliedPredictiveModeling)
library(pgmm)
library(rpart)
library(lubridate)
library(forecast)
library(e1071)
library(ElemStatLearn)
library(gbm)
library(elasticnet)
library(rpart.plot)
getwd()
setwd("C:/Users/lamti/Desktop/datasciencecoursera/Course 8 Practical machine learning/Week 4/Peer assessment")
data_test <- read.csv("pml-testing.csv", header = TRUE, na.strings = c("NA", "#DIV/0!", ""))
data_train <- read.csv("pml-training.csv", header = TRUE, na.strings = c("NA", "#DIV/0!", ""))
colnames(data_train)
colnames(data_test)
## remove columns that have NA as 95% of the observations for both data set
col_na_filter <- colSums(is.na(data_train))/nrow(data_train) < 0.95
training_data <- data_train[, col_na_filter == TRUE]
testing_data <- data_test[, col_na_filter == TRUE]
### Checking the two data sets have been successfully filtered
dim(training_data)
dim(testing_data)
## Removing the first 7 variables which do not related to the training model.
training_data <- training_data[,-c(1:7)]
testing_data <- testing_data[,-c(1:7)]
### Double check the we dont filtered out classe and problem_id
colnames(training_data)
colnames(testing_data)
## Creating data partition
inTrain = createDataPartition(y =training_data$classe, p = 3/4, list = FALSE)
training = training_data[ inTrain,]
testing = training_data[-inTrain,]
dim(training)
set.seed(19622)
model_rpart <- train(classe ~ ., data = training, method = "rpart")
predict_rpart <- predict(model_rpart, testing)
confusionMatrix(predict_rpart, testing$classe)
rpart.plot(model_rpart$finalModel)
## Random Forest model
model_rf <- train(classe ~ ., data = training, method = "rf", ntree = 100)
library(dplyr)
library(ggplot2)
library(caret)
library(AppliedPredictiveModeling)
library(pgmm)
library(rpart)
library(lubridate)
library(forecast)
library(e1071)
library(ElemStatLearn)
library(gbm)
library(elasticnet)
library(rpart.plot)
getwd()
data_test <- read.csv("pml-testing.csv", header = TRUE, na.strings = c("NA", "#DIV/0!", ""))
data_train <- read.csv("pml-training.csv", header = TRUE, na.strings = c("NA", "#DIV/0!", ""))
## remove columns that have NA as 95% of the observations for both data set
col_na_filter <- colSums(is.na(data_train))/nrow(data_train) < 0.95
training_data <- data_train[, col_na_filter == TRUE]
testing_data <- data_test[, col_na_filter == TRUE]
### Checking the two data sets have been successfully filtered
dim(training_data)
dim(testing_data)
## Removing the first 7 variables which do not related to the training model.
training_data <- training_data[,-c(1:7)]
testing_data <- testing_data[,-c(1:7)]
### Double check the we dont filtered out classe and problem_id
colnames(training_data)
colnames(testing_data)
## Creating data partition
inTrain = createDataPartition(y =training_data$classe, p = 3/4, list = FALSE)
training = training_data[ inTrain,]
testing = training_data[-inTrain,]
dim(training)
model_rpart <- train(classe ~ ., data = training, method = "rpart")
predict_rpart <- predict(model_rpart, testing)
confusionMatrix(predict_rpart, testing$classe)
rpart.plot(model_rpart$finalModel)
## Random Forest model
model_rf <- train(classe ~ ., data = training, method = "rf", ntree = 100)
predict_rf <- predict(model_rf, testing)
rf_cm <- confusionMatrix(predict_rf, testing$classe)
rf_cm
plot(rf_cm$table, main = "Random Forest Prediction Accuracy")
model_gbm <- train(classe ~ ., data = training, method = "gbm")
predict_gbm <- predict(model_gbm, training$classe, verbose = FALSE)
gbm_cm <- confusionMatrix(predict_gbm, testing$classe)
### Plotting GBM accuracy
plot(gbm_cm$table, main = "Gradient Boosting Model Accuracy level")
model_gbm <- train(classe ~ ., data = training, method = "gbm")
library(dplyr)
library(ggplot2)
library(caret)
library(AppliedPredictiveModeling)
library(pgmm)
library(rpart)
library(lubridate)
library(forecast)
library(e1071)
library(ElemStatLearn)
library(gbm)
library(elasticnet)
library(rpart.plot)
data_test <- read.csv("pml-testing.csv", header = TRUE, na.strings = c("NA", "#DIV/0!", ""))
data_train <- read.csv("pml-training.csv", header = TRUE, na.strings = c("NA", "#DIV/0!", ""))
colnames(data_train)
colnames(data_test)
## remove columns that have NA as 95% of the observations for both data set
col_na_filter <- colSums(is.na(data_train))/nrow(data_train) < 0.95
training_data <- data_train[, col_na_filter == TRUE]
testing_data <- data_test[, col_na_filter == TRUE]
## Removing the first 7 variables which do not related to the training model.
training_data <- training_data[,-c(1:7)]
testing_data <- testing_data[,-c(1:7)]
## Creating data partition
inTrain = createDataPartition(y =training_data$classe, p = 3/4, list = FALSE)
training = training_data[ inTrain,]
testing = training_data[-inTrain,]
dim(training)
model_rpart <- train(classe ~ ., data = training, method = "rpart")
model_rpart <- train(classe ~ ., data = training, method = "rpart")
predict_rpart <- predict(model_rpart, testing)
confusionMatrix(predict_rpart, testing$classe)
rpart.plot(model_rpart$finalModel)
## Random Forest model
model_rf <- train(classe ~ ., data = training, method = "rf", ntree = 100)
library(dplyr)
library(ggplot2)
library(caret)
library(AppliedPredictiveModeling)
library(pgmm)
library(rpart)
library(lubridate)
library(forecast)
library(e1071)
library(ElemStatLearn)
library(gbm)
library(elasticnet)
library(rpart.plot)
data_test <- read.csv("pml-testing.csv", header = TRUE, na.strings = c("NA", "#DIV/0!", ""))
data_train <- read.csv("pml-training.csv", header = TRUE, na.strings = c("NA", "#DIV/0!", ""))
## remove columns that have NA as 95% of the observations for both data set
col_na_filter <- colSums(is.na(data_train))/nrow(data_train) < 0.95
training_data <- data_train[, col_na_filter == TRUE]
testing_data <- data_test[, col_na_filter == TRUE]
### Checking the two data sets have been successfully filtered
dim(training_data)
dim(testing_data)
## Removing the first 7 variables which do not related to the training model.
training_data <- training_data[,-c(1:7)]
testing_data <- testing_data[,-c(1:7)]
### Double check the we dont filtered out classe and problem_id
colnames(training_data)
colnames(testing_data)
## Creating data partition
inTrain = createDataPartition(y =training_data$classe, p = 3/4, list = FALSE)
training = training_data[ inTrain,]
testing = training_data[-inTrain,]
dim(training)
set.seed(19622)
model_rpart <- train(classe ~ ., data = training, method = "rpart")
predict_rpart <- predict(model_rpart, testing)
confusionMatrix(predict_rpart, testing$classe)
rpart.plot(model_rpart$finalModel)
## Random Forest model
model_rf <- train(classe ~ ., data = training, method = "rf", ntree = 100)
predict_rf <- predict(model_rf, testing)
rf_cm <- confusionMatrix(predict_rf, testing$classe)
rf_cm
save.image("C:/Users/lamti/Desktop/datasciencecoursera/Course 8 Practical machine learning/Week 4/Peer assessment/Week 4 peer review assessment.RData")
#Cross validation
control <- trainControl(method = "cv", number = 3)
model_rpart <- train(classe ~ ., data = training, method = "rpart", trControl = control)
predict_rpart <- predict(model_rpart, testing)
confusionMatrix(predict_rpart, testing$classe)
rpart.plot(model_rpart$finalModel)
## Random Forest model
model_rf <- train(classe ~ ., data = training, method = "rf", ntree = 100, trControl = control)
predict_rf <- predict(model_rf, testing)
rf_cm <- confusionMatrix(predict_rf, testing$classe)
rf_cm
model_gbm <- train(classe ~ ., data = training, method = "gbm", verbose = FALSE, trControl = control)
predict_gbm <- predict(model_gbm, training$classe)
gbm_cm <- confusionMatrix(predict_gbm, testing$classe)
gbm_cm
model_rpart <- train(classe ~ ., data = training, method = "rpart", trControl = control)
predict_rpart <- predict(model_rpart, testing)
rpart_cm <- confusionMatrix(predict_rpart, testing$classe)
rpart_cm
model_gbm <- train(classe ~ ., data = training, method = "gbm", verbose = FALSE, trControl = control)
predict_gbm <- predict(model_gbm, training$classe)
gbm_cm <- confusionMatrix(predict_gbm, testing$classe)
gbm_cm
# Model selection
compare <- data.frame(Model = c("Decision Trees (CART)", "Random Forest", "Gradient Boosting"),
Accuracy = rbind(rpart_cm$overall[1], rf_cm$overall[1],
gbm_cm$overall[1]))
predict_gbm <- predict(model_gbm, testing$classe)
model_gbm <- train(classe ~ ., data = training, method = "gbm", verbose = FALSE, trControl = control)
predict_gbm <- predict(model_gbm, testing$classe)
gbm_cm <- confusionMatrix(predict_gbm, testing$classe)
gbm_cm
model_gbm <- train(classe ~ ., data = training, method = "gbm", verbose = FALSE, trControl = control)
predict_gbm <- predict(model_gbm, testing)
gbm_cm <- confusionMatrix(predict_gbm, testing$classe)
gbm_cm
model_gbm <- train(classe ~ ., data = training, method = "gbm", verbose = FALSE, trControl = control)
predict_gbm <- predict(model_gbm, testing)
gbm_cm <- confusionMatrix(predict_gbm, testing$classe)
gbm_cm
### Plotting GBM accuracy
plot(gbm_cm$table, main = "Gradient Boosting Model Accuracy level")
### Plotting GBM accuracy
plot(gbm_cm$table, main = "Gradient Boosting Model Accuracy level")
plot(gbm_cm$table, main = "Gradient Boosting Model Accuracy level")
# Model selection
compare <- data.frame(Model = c("Decision Trees (CART)", "Random Forest", "Gradient Boosting"),
Accuracy = rbind(rpart_cm$overall[1], rf_cm$overall[1],
gbm_cm$overall[1]))
compare
rpart_cm
## Creating data partition
set.seed(1234)
inTrain = createDataPartition(y =training_data$classe, p = 3/4, list = FALSE)
training = training_data[ inTrain,]
testing = training_data[-inTrain,]
#Cross validation
control <- trainControl(method = "cv", number = 3)
model_rpart <- train(classe ~ ., data = training, method = "rpart", trControl = control)
predict_rpart <- predict(model_rpart, testing)
rpart_cm <- confusionMatrix(predict_rpart, testing$classe)
rpart_cm
## Random Forest model
model_rf <- train(classe ~ ., data = training, method = "rf", ntree = 100, trControl = control)
predict_rf <- predict(model_rf, testing)
rf_cm <- confusionMatrix(predict_rf, testing$classe)
rf_cm
plot(rf_cm$table, main = "Random Forest Prediction Accuracy")
model_gbm <- train(classe ~ ., data = training, method = "gbm", verbose = FALSE, trControl = control)
predict_gbm <- predict(model_gbm, testing)
gbm_cm <- confusionMatrix(predict_gbm, testing$classe)
gbm_cm
compare <- data.frame(Model = c("Decision Trees (CART)", "Random Forest", "Gradient Boosting"),
Accuracy = rbind(rpart_cm$overall[1], rf_cm$overall[1],
gbm_cm$overall[1]))
compare
# Predicting test-data
pre_rf_test <- predict(model_rf, testing_data)
pre_rf_test
pred_result <- data.frame(Problem_id = testing_data$problem_id,
Prediction_outcome = pre_rf_test)
pred_result
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(caret)
library(dplyr)
library(ggplot2)
library(caret)
library(AppliedPredictiveModeling)
library(pgmm)
library(rpart)
library(lubridate)
library(forecast)
library(e1071)
library(ElemStatLearn)
library(gbm)
library(elasticnet)
library(rpart.plot)
getwd()
pred_result
compare
### Plotting GBM accuracy
plot(gbm_cm$table, main = "Gradient Boosting Model Accuracy level")
getwd()
setwd("C:/Users/lamti/Desktop/datasciencecoursera/Course 8 Practical machine learning/Week 4/Practical-Machine-Learning-week-4-Peer-Review-Project")
